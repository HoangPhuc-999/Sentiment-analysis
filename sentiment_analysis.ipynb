{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c64551",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Group: 1\n",
    "\n",
    "Member:\n",
    "- Thieu Dieu Thuy (Captain)\n",
    "- Nguyen Tran Tuan Kiet\n",
    "- Ly Thanh Long\n",
    "- Nguyen Thanh Mo\n",
    "- Ngo Hoang Phuc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b88936",
   "metadata": {},
   "source": [
    "### Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "cecead3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "69b51384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running for the first time, uncomment the following lines to download necessary NLTK datasets\n",
    "# nltk.download('twitter_samples')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4cce8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9f9c1c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4761ad9",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Make use of Logistic Regression model from scikit-learn or some other packages in Python, run\n",
    "the Sentiment Analysis solution again and make a very thorough comparison with what we\n",
    "implemented from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecaf50",
   "metadata": {},
   "source": [
    "#### Scratch Implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66959726",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3121f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        :tweet: a string\n",
    "    Output:\n",
    "        :tweets_clean: a list of words containing the processed tweet\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True) #the tokenizer will downcase everything except for emoticons\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and   # remove stopwords\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            stem_word = stemmer.stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cad67184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11397\n"
     ]
    }
   ],
   "source": [
    "def build_freqs(tweets, ys):\n",
    "    \"\"\" Build frequencies\n",
    "    Input:\n",
    "    tweets: a list of tweets\n",
    "    ys: an mx1 array with the sentiment label of each tweet (either 0 or 1)\n",
    "    Output:\n",
    "    freqs: a dictionary mapping each (word, sentiment) pair to its frequency\n",
    "    \"\"\"\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    # start with an empty dict and populate it by looping over all tweets\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs\n",
    "\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5af9393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        if (word, 1) in freqs.keys():\n",
    "            x[0,1] += freqs[(word, 1)]\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        if (word, 0) in freqs.keys():\n",
    "            x[0,2] += freqs[(word, 0)]\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d0ed8",
   "metadata": {},
   "source": [
    "Decision function: sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "422ff675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    ''' \n",
    "    h = 1. / (1. + np.exp(-z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6dfb8",
   "metadata": {},
   "source": [
    "Learning algorithm: Gradient descent, with loss function:\n",
    "\\begin{equation}\n",
    "    J = -\\frac{1}{m}\\sum_i (y_i \\log(\\hat{y_i}) + (1 - y_i)\\log(1-\\hat{y_i}))\n",
    "\\end{equation}\n",
    "\n",
    "Where $y_i = \\sigma (\\theta_0 + \\theta_1^Tx_1 + \\theta_2^Tx_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "9bc776f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_logistic(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    # get 'm', the number of rows in matrix X\n",
    "    m = len(x)\n",
    "    losses = []\n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x, theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = - (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h))) / float(m)\n",
    "        losses.append(float(J))\n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha * np.dot(x.T, (h-y))) / float(m)\n",
    "    \n",
    "    J = float(J)\n",
    "    \n",
    "    # plot the loss function\n",
    "    iter_list = np.arange(1, num_iters + 1, 1)\n",
    "    plt.plot(iter_list, losses, color='green', label='loss')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2bfc3d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/_wfh70cn569_5p6d24bj1_tr0000gn/T/ipykernel_99139/4011208994.py:27: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  losses.append(float(J))\n",
      "/var/folders/zg/_wfh70cn569_5p6d24bj1_tr0000gn/T/ipykernel_99139/4011208994.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.10157921.\n",
      "The resulting vector of weights is [np.float64(3e-07), np.float64(0.00127323), np.float64(-0.001111)]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, w = gradient_descent_logistic(X, Y, np.zeros((3,1)), 1e-9, 10000) # iters=epochs\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(w)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "50f891b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = np.squeeze(w)\n",
    "# Create a range for x1\n",
    "x1 = np.linspace(0, 10, 100)\n",
    "\n",
    "# Solve for x2 from equation g(x) = 0  w0 + w1*x1 + w2*x2 = 0\n",
    "x2 = -(params[0] + params[1]*x1) / params[2]\n",
    "\n",
    "# Plot the boundary\n",
    "plt.plot(x1, x2, 'r-', label='Decision Boundary (g(x)=0)')\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "e8b0a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "\n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet, freqs)\n",
    "    # make the prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x, theta))\n",
    "    \n",
    "    return y_pred[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "31708d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad -> 0.489459\n",
      "I am happy -> 0.546432\n",
      "I am bad -> 0.489459\n",
      "this movie should have been great. -> 0.539413\n",
      "great -> 0.538728\n",
      "great great -> 0.576993\n",
      "great great great -> 0.614357\n",
      "great great great great -> 0.650420\n",
      "This movie was so boring, it was almost entertaining. -> 0.498480\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function\n",
    "for tweet in ['bad','I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great', 'This movie was so boring, it was almost entertaining.']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, w)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae28c6",
   "metadata": {},
   "source": [
    "##### Determine the model accuracy \n",
    "* Use your 'predict_tweet' function to make predictions on each tweet in the test set.\n",
    "* If the prediction is > 0.5, set the model's classification 'y_hat' to 1, otherwise set the model's classification 'y_hat' to 0. 0.5 plays a role of the decision threshold here.\n",
    "* A prediction is accurate when the y_hat equals the test_y.  Sum up all the instances when they are equal and divide by $n$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "060410e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"   \n",
    "    # the list for storing predictions\n",
    "    y_hat = list()\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0.0)\n",
    "\n",
    "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
    "    accuracy = np.sum(y_hat == np.squeeze(test_y)) / len(test_y)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3e193129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9960\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, w)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06851221",
   "metadata": {},
   "source": [
    "##### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "56dd964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.47137167\tb'uff itna miss karhi thi ap :p'\n",
      "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
      "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
      "0\t0.53251630\tb'u prob fun david'\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "0\t0.50095500\tb'pat jay'\n",
      "THE TWEET IS: @bae_ts WHATEVER STIL L YOUNG &gt;:-(\n",
      "THE PROCESSED TWEET IS: ['whatev', 'stil', 'l', 'young', '>:-(']\n",
      "0\t0.50032454\tb'whatev stil l young >:-('\n",
      "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
      "0\t0.50000008\tb'belov grandmoth'\n",
      "THE TWEET IS: @CHEDA_KHAN Thats life. I get calls from people I havent seen in 20 years and its always favours : (\n",
      "THE PROCESSED TWEET IS: ['that', 'life', 'get', 'call', 'peopl', 'havent', 'seen', '20', 'year', 'alway', 'favour']\n",
      "0\t0.50564988\tb'that life get call peopl havent seen 20 year alway favour'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/_wfh70cn569_5p6d24bj1_tr0000gn/T/ipykernel_99139/2367174779.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "0\t0.51644293\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n",
      "THE TWEET IS: @ITVCentral #Midlands Yes thanks for the depressing weather forecast, where the word 'rain' was mentioned several times :-(\n",
      "THE PROCESSED TWEET IS: ['midland', 'ye', 'thank', 'depress', 'weather', 'forecast', 'word', 'rain', 'mention', 'sever', 'time', ':-(']\n",
      "0\t0.53527788\tb'midland ye thank depress weather forecast word rain mention sever time :-('\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "print('Label Predicted Tweet')\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, w)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6afe8d",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Implementation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ec9c1b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Logistic Accuracy: 0.995\n"
     ]
    }
   ],
   "source": [
    "train_x_vec = np.zeros((len(train_x),3))\n",
    "for i in range(len(train_x)):\n",
    "    train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "test_x_vec = np.zeros((len(test_x),3))\n",
    "for i in range(len(test_x)):\n",
    "    test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "\n",
    "y_pred = model.predict(test_x_vec[:, 1:])\n",
    "\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "print(\"Sklearn Logistic Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "23f72bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Logistic Prediction for 'bad': [[0.48092163 0.51907837]]\n"
     ]
    }
   ],
   "source": [
    "tweet = \"bad\"\n",
    "print(\"Sklearn Logistic Prediction for 'bad':\", model.predict_proba(extract_features(tweet, freqs)[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c9357",
   "metadata": {},
   "source": [
    "##### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0390b24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet (sklearn)\n",
      "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "True label: [1.] Predicted: 0.0\n",
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "True label: [1.] Predicted: 0.0\n",
      "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
      "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: @bumkeyyfel b-butt : ( isn't black cat a bad luck ene\n",
      "THE PROCESSED TWEET IS: ['b-butt', 'black', 'cat', 'bad', 'luck', 'ene']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: @bae_ts WHATEVER STIL L YOUNG &gt;:-(\n",
      "THE PROCESSED TWEET IS: ['whatev', 'stil', 'l', 'young', '>:-(']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: don't sleep. I'm here : (\n",
      "THE PROCESSED TWEET IS: ['sleep']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: the internet is being a total bitch : (\n",
      "THE PROCESSED TWEET IS: ['internet', 'total', 'bitch']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
      "True label: [0.] Predicted: 1.0\n",
      "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "True label: [0.] Predicted: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Label Predicted Tweet (sklearn)')\n",
    "for x,y in zip(test_x, test_y):   #  y phi dng tweet gc\n",
    "    x_vec = extract_features(x, freqs)   # build feature vector (ging khi train sklearn)\n",
    "    y_hat = model.predict(x_vec[:, 1:])[0]      # dng model  fit\n",
    "    if y != y_hat:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('True label:', y, 'Predicted:', y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b5d17",
   "metadata": {},
   "source": [
    "#### A Detailed Comparison of the Two Methods\n",
    "\n",
    "a. Simplicity and Development Speed:\n",
    "\n",
    "- From Scratch: This method requires the programmer to have a deep understanding of the mathematics behind the algorithm. This process is time-consuming, labor-intensive, and prone to bugs, especially those related to numerical calculations.\n",
    "\n",
    "- Scikit-learn abstracts away all the complex mathematics internally. The user does not need to worry about implementing the Sigmoid function, cost function, or Gradient Descent.\n",
    "\n",
    "b. Prediction Differences:\n",
    "\n",
    "- The models produce slightly different probability scores, especially around the decision boundary of 0.5, leading to some tweets being classified differently.\n",
    "\n",
    "c. Practical Impact:\n",
    "\n",
    "- While the models generally align, discrepancies near the decision threshold could affect the final sentiment classification of some tweets.\n",
    "\n",
    "d. Reliability and optimization:\n",
    "\n",
    "- Sklearn uses standard optimization algorithms (liblinear, lbfgs, sag, saga)  more stable, faster, and easier to scale to large datasets.\n",
    "\n",
    "- Custom implementation: good for learning and understanding the fundamentals, but it may encounter convergence issues if the dataset is large or has many features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a71f3",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "In this line of code, if we change the number of iterations to, say, 100K, you might get some\n",
    "divided by zero error. Explain why and find a correction.\n",
    "```python\n",
    "gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f0f0e",
   "metadata": {},
   "source": [
    "Cause: When the number of iterations is increased to 100,000, the gradient descent algorithm may converge to the optimal value, and the sigmoid function returns values very close to 0 or 1. When computing np.log(h) or np.log(1-h), if h = 0 or h = 1, we encounter the log(0) error.\n",
    "\n",
    "Solution:\n",
    "Add a small epsilon to avoid log(0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a6816d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_gradient_descent_logistic(x, y, theta, alpha, num_iters):\n",
    "    m = len(x)\n",
    "    losses = []\n",
    "    eps = 1e-7  # Epsilon nh  trnh log(0)\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        z = np.dot(x, theta)\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # Clamp h  trnh log(0)\n",
    "        h = np.clip(h, eps, 1 - eps)\n",
    "        \n",
    "        # Tnh cost function vi epsilon\n",
    "        J = -(np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h))) / float(m)\n",
    "        losses.append(float(J))\n",
    "        \n",
    "        # Update weights\n",
    "        theta = theta - (alpha * np.dot(x.T, (h-y))) / float(m)\n",
    "\n",
    "    J = float(J)\n",
    "    \n",
    "    # Plot loss\n",
    "    iter_list = np.arange(1, num_iters + 1, 1)\n",
    "    plt.plot(iter_list, losses, color='green', label='loss')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8d6b54a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/_wfh70cn569_5p6d24bj1_tr0000gn/T/ipykernel_99139/3334272438.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  losses.append(float(J))\n",
      "/var/folders/zg/_wfh70cn569_5p6d24bj1_tr0000gn/T/ipykernel_99139/3334272438.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.05666520.\n",
      "The resulting vector of weights is [np.float64(1.17e-06), np.float64(0.00280679), np.float64(-0.00210874)]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, w = fixed_gradient_descent_logistic(X, Y, np.zeros((3, 1)), 1e-9, 100000)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(w)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f38f2",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "In Feature Engineering part, given a sentence s, we build two features: the positive frequency of s and the negative frequency of s. Given a sentence s, normalize these two features with respect to \n",
    "```python\n",
    "N = train_set_length * the length of s.\n",
    "``` \n",
    "Compare your result with the original one in the course. Is that normalization a good thing to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ccad5594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: bad\n",
      "Original prob positive:   0.519078\n",
      "Normalized prob positive: 0.618394\n",
      "--------------------------------------------------\n",
      "Tweet: bad bad\n",
      "Original prob positive:   0.418220\n",
      "Normalized prob positive: 0.618394\n",
      "--------------------------------------------------\n",
      "Tweet: bad bad bad\n",
      "Original prob positive:   0.323765\n",
      "Normalized prob positive: 0.618394\n",
      "--------------------------------------------------\n",
      "Tweet: bad bad bad bad\n",
      "Original prob positive:   0.241778\n",
      "Normalized prob positive: 0.618394\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bunnypro/miniconda3/envs/ml_env/lib/python3.11/site-packages/sklearn/utils/validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    words = process_tweet(tweet)\n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1    \n",
    "    # loop through each word in the list of words\n",
    "    for word in words:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        if (word, 1) in freqs.keys():\n",
    "            x[0,1] += freqs[(word, 1)]\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        if (word, 0) in freqs.keys():\n",
    "            x[0,2] += freqs[(word, 0)]\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x\n",
    "\n",
    "def extract_features_normalized(tweet, freqs, N, process_tweet=process_tweet):\n",
    "    words = process_tweet(tweet)\n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1\n",
    "    for w in words:\n",
    "        x[0,1] += freqs.get((w, 1), 0)\n",
    "        x[0,2] += freqs.get((w, 0), 0)\n",
    "    # normalize\n",
    "    x[0,1] = x[0,1] / (N * len(words))\n",
    "    x[0,2] = x[0,2] / (N * len(words))\n",
    "    return x\n",
    "\n",
    "def train_model(train_x, train_y, freqs):\n",
    "    X_train = np.vstack([extract_features(t, freqs) for t in train_x])\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train[:, 1:], train_y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_task3(model, freqs, N, tweet):\n",
    "    x_orig = extract_features(tweet, freqs)\n",
    "    prob_orig = model.predict_proba(x_orig[:, 1:])[0][1]\n",
    "\n",
    "    x_norm = extract_features_normalized(tweet, freqs, N)\n",
    "    prob_norm = model.predict_proba(x_norm[:, 1:])[0][1]\n",
    "\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    print(f\"Original prob positive:   {prob_orig:.6f}\")\n",
    "    print(f\"Normalized prob positive: {prob_norm:.6f}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "\n",
    "N = len(train_x)\n",
    "model = train_model(train_x, train_y, freqs)\n",
    "\n",
    "# Test vi cc tweet bt k\n",
    "test_task3(model, freqs, N, \"bad\")\n",
    "test_task3(model, freqs, N, \"bad bad\")\n",
    "test_task3(model, freqs, N, \"bad bad bad\")\n",
    "test_task3(model, freqs, N, \"bad bad bad bad\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40066e16",
   "metadata": {},
   "source": [
    "From the results:\n",
    "\n",
    "- Original features:  \n",
    "  The probability that the tweet has positive sentiment changes when the same word is repeated multiple times in the tweet.  \n",
    "  For example:  \n",
    "  - \"bad\"  prob  0.519078\n",
    "  - \"bad bad bad bad\"  prob   0.241778\n",
    "  This shows that the models prediction is influenced by the frequency of a word in the tweet.\n",
    "\n",
    "- Normalized features:  \n",
    "  The probability becomes constant regardless of how many times the word is repeated.  \n",
    "  - \"bad\", \"bad bad\", \"bad bad bad bad\"  prob  0.618394  \n",
    "  Word repetition no longer affects the prediction. In fact, the probability of approximately 0.62 is considered \"Positive\", which is not true for this sentence.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Normalization removes the effect of word frequency on prediction.  \n",
    "- Advantage: Makes the model less sensitive to repeated words, which can reduce bias from spammy tweets.  \n",
    "- Disadvantage: Loses information about word emphasis (e.g., \"bad bad bad\" is stronger than just \"bad\").  \n",
    "\n",
    " In practice, normalization may not always be a good idea because repetition can carry useful sentiment intensity.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abdccf",
   "metadata": {},
   "source": [
    "### Task 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1f304b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature matrix for train/test\n",
    "train_vec = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    train_vec[i, :] = extract_features(train_x[i], freqs)\n",
    "\n",
    "test_vec = np.zeros((len(test_x), 3))\n",
    "for i in range(len(test_x)):\n",
    "    test_vec[i, :] = extract_features(test_x[i], freqs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "31ac93f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-17 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-17 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-17 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-17 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-17 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-17 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-17 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-17 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-17 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "train_minmax = train_vec.copy()\n",
    "train_minmax[:, 1:] = scaler_minmax.fit_transform(train_vec[:, 1:])  # fit + transform train\n",
    "\n",
    "test_minmax = test_vec.copy()\n",
    "test_minmax[:, 1:] = scaler_minmax.transform(test_vec[:, 1:])  # ch transform test\n",
    "\n",
    "model_minmax = LogisticRegression()\n",
    "model_minmax.fit(train_minmax[:, 1:], train_y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "cd26128d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-16 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-16 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-16 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-16 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-16 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Standard Scaling (Z-score)\n",
    "scaler_standard = StandardScaler()\n",
    "train_standard = train_vec.copy()\n",
    "train_standard[:, 1:] = scaler_standard.fit_transform(train_vec[:, 1:])  # fit + transform train\n",
    "\n",
    "test_standard = test_vec.copy()\n",
    "test_standard[:, 1:] = scaler_standard.transform(test_vec[:, 1:])  # ch transform test\n",
    "\n",
    "model_standard = LogisticRegression()\n",
    "model_standard.fit(train_standard[:, 1:], train_y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ea50214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet: I am very happy today\n",
      "Probability Positive (Original features): 0.8250\n",
      "Probability Positive (Min-Max scaled):   0.6940\n",
      "Probability Positive (Standard scaled):  0.6307\n",
      "\n",
      "Accuracy Comparison\n",
      "Original Features:  0.9950\n",
      "Min-Max Scaled:     0.9430\n",
      "Standard Scaled:    0.9540\n"
     ]
    }
   ],
   "source": [
    "def test_task4(tweet):\n",
    "    # original\n",
    "    x_vec = extract_features(tweet, freqs).reshape(1, -1)\n",
    "    prob_orig = model.predict_proba(x_vec[:, 1:])[0][1]\n",
    "\n",
    "    # min-max\n",
    "    x_minmax = x_vec.copy()\n",
    "    x_minmax[:, 1:] = scaler_minmax.transform(x_vec[:, 1:])\n",
    "    prob_minmax = model_minmax.predict_proba(x_minmax[:, 1:])[0][1]\n",
    "\n",
    "    # standard\n",
    "    x_standard = x_vec.copy()\n",
    "    x_standard[:, 1:] = scaler_standard.transform(x_vec[:, 1:])\n",
    "    prob_standard = model_standard.predict_proba(x_standard[:, 1:])[0][1]\n",
    "\n",
    "    # In kt qu probability\n",
    "    print(f\"\\nTweet: {tweet}\")\n",
    "    print(f\"Probability Positive (Original features): {prob_orig:.4f}\")\n",
    "    print(f\"Probability Positive (Min-Max scaled):   {prob_minmax:.4f}\")\n",
    "    print(f\"Probability Positive (Standard scaled):  {prob_standard:.4f}\")\n",
    "\n",
    "    # In thm accuracy comparison\n",
    "    acc_orig = accuracy_score(test_y, model.predict(test_vec[:, 1:]))\n",
    "    acc_minmax = accuracy_score(test_y, model_minmax.predict(test_minmax[:, 1:]))\n",
    "    acc_standard = accuracy_score(test_y, model_standard.predict(test_standard[:, 1:]))\n",
    "\n",
    "    print(\"\\nAccuracy Comparison\")\n",
    "    print(f\"Original Features:  {acc_orig:.4f}\")\n",
    "    print(f\"Min-Max Scaled:     {acc_minmax:.4f}\")\n",
    "    print(f\"Standard Scaled:    {acc_standard:.4f}\")\n",
    "\n",
    "test_task4(\"I am very happy today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad5dfd",
   "metadata": {},
   "source": [
    "In this task, we applied two common feature scaling techniques  Min-Max Scaling and Standard Scaling (Z-score)  to the feature vectors before training logistic regression.  \n",
    "\n",
    "Observations:\n",
    "\n",
    "- For individual test tweets, the predicted probabilities of being positive changed noticeably after applying scaling.  \n",
    "  - With Min-Max Scaling, the probability often increased slightly compared to the original.  \n",
    "  - With Standard Scaling, the probability sometimes decreased, showing a different interpretation of feature distribution.  \n",
    "- On the test set, the accuracy comparison was:  \n",
    "  - Original features: 0.9950  \n",
    "  - Min-Max scaled: 0.9430 \n",
    "  - Standard scaled: 0.9540  \n",
    "\n",
    "Remarks:\n",
    "\n",
    "- Scaling did not improve accuracy in this dataset. In fact, the original feature representation yielded the best performance.  \n",
    "- The reason is that our feature values are already simple frequency counts (non-negative, small magnitude), so logistic regression handles them well without scaling.  \n",
    "- Min-Max and Standard scaling are generally more useful when features have different ranges or units (e.g., combining word frequencies with continuous numerical features).  \n",
    "- In this context, scaling caused some loss of information about the raw frequency magnitude, which slightly reduced model performance.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "While feature scaling is important in many machine learning pipelines, for this task (frequency-based features in sentiment analysis), scaling was not beneficial and the original features worked better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8ac45",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "During the session, I gave a natural way to end up with Logistic Regression as the decision function for our Sentiment Analysis problem. Lets come up with another decision function. Let\n",
    "\\begin{equation}\n",
    "g(s) = \\begin{cases}\n",
    "1, \\quad &\\text{if positive frequency > negative frequency} \\\\\n",
    "0, \\quad &\\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Note that g(s) =1 means the sentence s has positive sentiment.\n",
    "\n",
    "With such mathematical formulation, recompute the precision on the test set. Compare and Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "671a606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_lr(test_x, test_y, freqs, theta):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    for tweet, actual in zip(test_x, test_y):\n",
    "        predicted = predict_tweet(tweet, freqs, theta)\n",
    "        if predicted > 0.5:\n",
    "            if actual == 1:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "    accuracy = true_pos / (true_pos + false_pos)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf423a7f",
   "metadata": {},
   "source": [
    "Decision function:\n",
    "\n",
    "\\begin{equation}\n",
    "g(s) = \\begin{cases}\n",
    "1, \\quad &\\text{if positive frequency > negative frequency} \\\\\n",
    "0, \\quad &\\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5f9ef3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tweet(tweet, freqs):\n",
    "    x = extract_features(tweet, freqs)\n",
    "    if x[0,1] > x[0,2]:\n",
    "        y_pred = 1\n",
    "    else:\n",
    "        y_pred = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ccb9b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_gfunc(test_x, test_y, freqs):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    for tweet, actual in zip(test_x, test_y):\n",
    "        predicted = classify_tweet(tweet, freqs)\n",
    "        if predicted == 1:\n",
    "            if actual == 1:\n",
    "                true_pos += 1\n",
    "            else:\n",
    "                false_pos += 1\n",
    "        \n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "20cdd8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's precision = 0.9921\n",
      "g(s) function's precision = 0.9960\n"
     ]
    }
   ],
   "source": [
    "pre_lr = accuracy_lr(test_x, test_y, freqs, w)\n",
    "print(f\"Logistic regression model's precision = {pre_lr:.4f}\")\n",
    "\n",
    "pre_gfunc = accuracy_gfunc(test_x, test_y, freqs)\n",
    "print(f\"g(s) function's precision = {pre_gfunc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ce74e",
   "metadata": {},
   "source": [
    "It can be seen that the accuracy of the function g(s) is higher than the accuracy of the logistic regression model. This is because the function g(s) is based only on the number of positive words compared to the number of negative words, whereas the logistic regression model relies on the interactions and correlations between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0aa76",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "7949717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_6_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    x = np.zeros((1, 7)) \n",
    "    \n",
    "    x[0,0] = 1\n",
    "\n",
    "    for word in word_l:\n",
    "        if (word, 1) in freqs.keys():\n",
    "            x[0,1] += freqs.get((word, 1)) # x1\n",
    "        \n",
    "        if (word, 0) in freqs.keys():\n",
    "            x[0,2] += freqs.get((word, 0)) # x2\n",
    "    \n",
    "    x[0,3] = 1 if 'no' in tweet.lower().split() else 0 # x3\n",
    "\n",
    "    for word in word_l:\n",
    "        if word in ['I', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves']:\n",
    "            x[0,4] += 1 # x4\n",
    "\n",
    "    x[0,5] = 1 if '!' in tweet else 0 # x5\n",
    "\n",
    "    x[0,6] = np.log(len(word_l) + 1) # x6\n",
    "\n",
    "    assert(x.shape == (1, 7))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "5501dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00846345 -0.00964128  0.35545727  0.02133365 -0.38931978 -0.09614912]] [0.65054759]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 7))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_6_features(train_x[i], freqs)\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "model = LogisticRegression(verbose=1, max_iter=10000, random_state=42)\n",
    "# drop x0 because it's bias and sklearn adds it automatically\n",
    "model.fit(X[:,1:7], Y.ravel())\n",
    "print(model.coef_, model.intercept_)\n",
    "# # Apply gradient descent\n",
    "# J, w = gradient_descent_logistic(X, Y, np.random.normal(0, 0.01, size=(7, 1)), 1e-5, 10000)\n",
    "# print(f\"The cost after training is {J:.8f}.\")\n",
    "# print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(w)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "73f66de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    x = extract_6_features(tweet, freqs)\n",
    "    y_pred = model.predict_proba(np.dot(x[:, 1:7], theta) + model.intercept_.reshape(1, -1))\n",
    "    # Return scalar value instead of 2D array\n",
    "    return y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "392428c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.855874\n",
      "I am bad -> 0.545316\n",
      "this movie should have been great. -> 0.820956\n",
      "great -> 0.829466\n",
      "great great -> 0.926954\n",
      "great great great -> 0.971002\n",
      "great great great great -> 0.988877\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function\n",
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    x_features = extract_6_features(tweet, freqs)\n",
    "    prob = model.predict_proba(x_features[:, 1:7])[0][1]  # Get probability of positive class\n",
    "    print( '%s -> %f' % (tweet, prob))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "515e370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    \"\"\"Prints precision for Positive=1 and Negative=0, plus full report and confusion matrix.\"\"\"\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "    print(\"Confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(f\"\\nROC-AUC: {roc_auc_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "40a90366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression with 6 features ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.99      0.99      1000\n",
      "    Positive       0.99      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       1.00      0.99      0.99      2000\n",
      "weighted avg       1.00      0.99      0.99      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[992   8]\n",
      " [  2 998]]\n",
      "\n",
      "ROC-AUC: 0.995\n"
     ]
    }
   ],
   "source": [
    "test_vec = np.zeros((len(test_x), 7))\n",
    "for i in range(len(test_x)):\n",
    "    test_vec[i, :] = extract_6_features(test_x[i], freqs)\n",
    "\n",
    "y_pred = model.predict(test_vec[:, 1:7])\n",
    "evaluate_model(\"Logistic Regression with 6 features\", test_y, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a37d7f",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 100% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 100% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The scores of 0.99 and 1 are extremely high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a nearly perfect 99%.\n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 998: 998 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 8: 8 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 2: 2 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 992: 992 samples were correctly classified as \"Negative\".\n",
    "\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.995 is very close to 1.0, which means our model is highly effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777f229",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "In your opinion, can we do better? I propose that your team try all ML models that you know and give us the model with the best possible precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c10d93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    \"\"\"Prints precision for Positive=1 and Negative=0, plus full report and confusion matrix.\"\"\"\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "    print(\"Confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(f\"\\nROC-AUC: {roc_auc_score(y_true, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da9f2c",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d6e606f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.93      0.99      0.96      1000\n",
      "    Positive       0.99      0.92      0.95      1000\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.96      0.96      0.95      2000\n",
      "weighted avg       0.96      0.95      0.95      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[986  14]\n",
      " [ 76 924]]\n",
      "\n",
      "ROC-AUC: 0.955\n"
     ]
    }
   ],
   "source": [
    "def run_logistic_regression():\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "\n",
    "    y_pred = model.predict(test_x_vec[:, 1:])\n",
    "    evaluate_model(\"Logistic Regression\", test_y, y_pred)\n",
    "    return model\n",
    "\n",
    "lr_model = run_logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ebdbc",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 93% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 92% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The scores of 0.96 and 0.95 are very high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a high 95%.\n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 924: 924 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 14: 14 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 76: 76 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 986: 986 samples were correctly classified as \"Negative\".\n",
    "\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.955 is very close to 1.0, which means our model is highly effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b7ce3",
   "metadata": {},
   "source": [
    "##### Random Forest\n",
    "- Decision Tree: splitting data into branches based on feature values, forming a tree-like structure. \n",
    "- Random Forest: ensemble learning algorithm with multiple decision trees, each of which will get a random sample of data points. Each split in the tree considers a random subset of features (feature bagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4896a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.99      0.99      0.99      1000\n",
      "    Positive       0.99      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[994   6]\n",
      " [  5 995]]\n",
      "\n",
      "ROC-AUC: 0.9945\n"
     ]
    }
   ],
   "source": [
    "def run_random_forest_classification():\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "    y_pred = rf.predict(test_x_vec[:, 1:])\n",
    "    \n",
    "    evaluate_model(\"Random Forest\", test_y, y_pred)\n",
    "    return rf\n",
    "\n",
    "rf = run_random_forest_classification()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52124f2",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The score of 0.99 for both classes is very high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a nearly perfect 99%.\n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 995: 995  samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 6: 6 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 5: 5 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 994: 994 samples were correctly classified as \"Negative\".\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.9945 is very close to 1.0, which means our model is extremely effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29b56d",
   "metadata": {},
   "source": [
    "##### XGBoost (Extreme Gradient Boosting)\n",
    "Core idea:\n",
    "- Build an ensemble of decision trees, but sequentially (each new tree corrects the errors of the previous ones).\n",
    "- Gradient descent to minimize the loss function, with regularization to prevent overfitting.\n",
    "- Support missing values handling and sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ef4e1221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.99      0.99      0.99      1000\n",
      "    Positive       0.99      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[993   7]\n",
      " [  6 994]]\n",
      "\n",
      "ROC-AUC: 0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bunnypro/miniconda3/envs/ml_env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [09:33:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "def run_xgboost_classification():\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    xgb.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "    y_pred = xgb.predict(test_x_vec[:, 1:])\n",
    "    \n",
    "    evaluate_model(\"XGBoost\", test_y, y_pred)\n",
    "    return xgb\n",
    "\n",
    "xgb = run_xgboost_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b4ee2",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The score of 0.99 for both classes is very high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a nearly perfect 99%.\n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 994: 994 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 7: 7 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 6: 6 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 993: 993 samples were correctly classified as \"Negative\".\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.9935 is very close to 1.0, which means our model is highly effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf6dca",
   "metadata": {},
   "source": [
    "##### Linear SVM\n",
    "- Find the best hyperplane separating data points of different classes in a feature space.\n",
    "    - Linear kernel: decision boundary is a straight line, a plane or hyperplane.\n",
    "    - SVM maximizes the distance (margin) between hyperplane and the closest data points (support vectors)\n",
    "    - Decision function:\n",
    "    \\begin{equation}\n",
    "    f(x) = wx + b\n",
    "    \\end{equation}\n",
    "    - If $f(x) \\geq 0$, classify as $+1$.\n",
    "    - If $f(x) < 0$, classify as $-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6668f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Linear SVM ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.99      0.99      1000\n",
      "    Positive       0.99      1.00      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[989  11]\n",
      " [  2 998]]\n",
      "\n",
      "ROC-AUC: 0.9934999999999999\n"
     ]
    }
   ],
   "source": [
    "def run_linear_svm_classification():\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "    svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "    svm.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "    y_pred = svm.predict(test_x_vec[:, 1:])\n",
    "    \n",
    "    evaluate_model(\"Linear SVM\", test_y, y_pred)\n",
    "    return svm\n",
    "\n",
    "lin_svm = run_linear_svm_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71aa2b",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 100% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 100% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The score of 0.99 for both classes is very high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a nearly perfect 99%, \n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 998: 998 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 11: 11 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 2: 2 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 989: 989 samples were correctly classified as \"Negative\".\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.9935 is very close to 1.0, which means our model is highly effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40551b38",
   "metadata": {},
   "source": [
    "##### RBF (Radial Basis Function) SVM\n",
    "- Unlike Linear SVM, which uses linear kernel to draw linear decision function, RBF SVM uses RBF kernel to create curved, flexible decision boundaries, therefore handle nonlinear classification problems.\n",
    "- RBF Kernel function:\n",
    "\\begin{equation}\n",
    "K(x, x) = \\exp(-\\gamma \\|x - x\\|^2)\n",
    "\\end{equation}\n",
    "\t- $\\gamma$ controls how far the influence of a single training sample reaches.\n",
    "\t- Small $\\gamma$: smoother boundary, risk of underfitting.\n",
    "\t- Large $\\gamma$: tighter boundary around data points, risk of overfitting.\n",
    "\n",
    "- \tRegularization parameter (C):\n",
    "\t- Large C: tries to classify all training examples correctly (low bias, high variance).\n",
    "\t- Small C: allows some misclassifications but generalizes better (high bias, low variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c127b252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RBF SVM ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.99      0.99      1000\n",
      "    Positive       0.99      1.00      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[989  11]\n",
      " [  2 998]]\n",
      "\n",
      "ROC-AUC: 0.9934999999999999\n"
     ]
    }
   ],
   "source": [
    "def run_rbf_svm_classification():\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "    svm = SVC(kernel='rbf', C=1, gamma=\"scale\", random_state=42)\n",
    "    svm.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "    y_pred = svm.predict(test_x_vec[:, 1:])\n",
    "    \n",
    "    evaluate_model(\"RBF SVM\", test_y, y_pred)\n",
    "    return svm\n",
    "\n",
    "rbf_svm = run_rbf_svm_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303c9c5",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 100% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 100% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The score of 0.99 for both classes is very high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a nearly perfect 99%, \n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 998: 998 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 11: 11 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 2: 2 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 989: 989 samples were correctly classified as \"Negative\".\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.9935 is very close to 1.0, which means our model is highly effective.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330cf4a9",
   "metadata": {},
   "source": [
    "##### Naive Bayes\n",
    "- Simple but powerfull probabilistic classifiers based on Bayes' theorem with assumption that features are conditionally independent given the class.\n",
    "- Bayes theorem:\n",
    "\\begin{equation}\n",
    "P(y \\mid X) = \\frac{P(X \\mid y) \\, P(y)}{P(X)}\n",
    "\\end{equation}\n",
    "where\n",
    "    - $P(y \\mid X)$ = posterior probability of class $y$ given features $X$\n",
    "    - $P(X \\mid y)$ = likelihood of observing features $X$ under class $y$\n",
    "    - $P(y)$ = prior probability of class $y$\n",
    "    - $P(X)$ = evidence (normalizing constant)\n",
    "- Nave assumption:\n",
    "Features are independent:\n",
    "\\begin{equation}\n",
    "P(X \\mid y) = \\prod_{i=1}^n P(x_i \\mid y)\n",
    "\\end{equation}\n",
    "- For this problem, we will use Multinomial Naive Bayes, since we count word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "53f1cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive Bayes ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.50      1.00      0.67      1000\n",
      "    Positive       0.82      0.01      0.02      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.66      0.50      0.34      2000\n",
      "weighted avg       0.66      0.50      0.34      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[998   2]\n",
      " [991   9]]\n",
      "\n",
      "ROC-AUC: 0.5035\n"
     ]
    }
   ],
   "source": [
    "def run_naive_bayes_classification():\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "\n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(train_x_vec[:, 1:], train_y.ravel())\n",
    "    y_pred = nb.predict(test_x_vec[:, 1:])\n",
    "    \n",
    "    evaluate_model(\"Naive Bayes\", test_y, y_pred)\n",
    "    return nb\n",
    "\n",
    "nb = run_naive_bayes_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ca1d8",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 50% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 82% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 100% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 0.01% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The score of 0.67 for class \"Negative\" is fine, but the score of 0.02 for class \"Positive\" is extremely low, meaning there is an unbalance between Precision and Recall.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is 50%, far lower than our Logistic Regression.\n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 9: 9 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 2: 2 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 991: 991 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 998: 998 samples were correctly classified as \"Negative\".\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.5035 is very close to 0.5, which means our model just has random guess, no discriminative ability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96030394",
   "metadata": {},
   "source": [
    "##### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "05b29170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bunnypro/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step\n",
      "\n",
      "=== Deep Neural Network ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.99      0.99      1000\n",
      "    Positive       0.99      1.00      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[986  14]\n",
      " [  1 999]]\n",
      "\n",
      "ROC-AUC: 0.9925\n"
     ]
    }
   ],
   "source": [
    "def run_dnn_classification():\n",
    "    # Prepare feature vectors\n",
    "    train_x_vec = np.zeros((len(train_x),3))\n",
    "    for i in range(len(train_x)):\n",
    "        train_x_vec[i,:] = extract_features(train_x[i],freqs)\n",
    "    test_x_vec = np.zeros((len(test_x),3))\n",
    "    for i in range(len(test_x)):\n",
    "        test_x_vec[i,:] = extract_features(test_x[i],freqs)\n",
    "    \n",
    "    # Use only the 2 feature columns (excluding bias at index 0)\n",
    "    train_features = train_x_vec[:, 1:]  # Shape: (n_samples, 2)\n",
    "    test_features = test_x_vec[:, 1:]    # Shape: (n_samples, 2)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(train_features.shape[1],)),  # input_shape=(2,)\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear') \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "    # Train on full training set\n",
    "    model.fit(train_features, train_y.ravel(), \n",
    "              epochs=200,  \n",
    "              batch_size=16,\n",
    "              verbose=0,\n",
    "              validation_split=0.2)  # Use 20% for validation during training\n",
    "    \n",
    "    # Get predictions on test set\n",
    "    y_pred_logits = model.predict(test_features)\n",
    "    y_pred = (y_pred_logits > 0).astype(int).ravel()  # Use 0 as threshold for logits\n",
    "    \n",
    "    # Apply evaluate_model function\n",
    "    evaluate_model(\"Deep Neural Network\", test_y.ravel(), y_pred)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run the DNN classification\n",
    "dnn_model = run_dnn_classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66850a",
   "metadata": {},
   "source": [
    "The output section shows the evaluation of the model on the test dataset, which consists of 2000 samples (1000 \"Negative\" and 1000 \"Positive\").\n",
    "\n",
    "1. Classification Report:\n",
    "- This report breaks down the model's performance for each class.\n",
    "\n",
    "    - Precision: Of all the predictions the model made for a class, how many were correct?\n",
    "\n",
    "        - It was correct 100% of the time it predicted \"Negative\".\n",
    "\n",
    "        - It was correct 99% of the time it predicted \"Positive\".\n",
    "\n",
    "    - Recall (Sensitivity): Of all the actual instances of a class, how many did the model correctly identify?\n",
    "\n",
    "        - It correctly identified 99% of all actual \"Negative\" samples.\n",
    "\n",
    "        - It correctly identified 100% of all actual \"Positive\" samples.\n",
    "\n",
    "    - F1-Score: The harmonic mean of Precision and Recall. It provides a single metric to balance both concerns. The score of 0.99 for both classes is very high, indicating excellent performance.\n",
    "\n",
    "    - Accuracy: The overall percentage of correct predictions, which is a nearly perfect 99%.\n",
    "\n",
    "2. Confusion Matrix\n",
    "    - True Positives (TP) = 999: 999 samples were correctly classified as \"Positive\".\n",
    "\n",
    "    - False Positives (FP) = 14: 14 \"Negative\" samples were incorrectly classified as \"Positive\".\n",
    "\n",
    "    - False Negatives (FN) = 1: 1 \"Positive\" samples were incorrectly classified as \"Negative\".\n",
    "\n",
    "    - True Negatives (TN) = 986: 986 samples were correctly classified as \"Negative\".\n",
    "\n",
    "3. ROC-AUC:\n",
    "- The AUC score ranges from 0 to 1, where:\n",
    "\n",
    "    - 1.0: A perfect classifier.\n",
    "\n",
    "    - 0.5: A model with no discriminative ability (equivalent to a random guess).\n",
    "\n",
    "    - 0.0: A model that gets every prediction wrong.\n",
    "\n",
    "- Our score of 0.9925 is very close to 1, indicating an excellent performance,\n",
    "\n",
    "4. Additional Notes:\n",
    "- The performance varies for each train, but overall, DNN shows a capability in sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd9e7a",
   "metadata": {},
   "source": [
    "##### Model Comparison Table - Task 7\n",
    "\n",
    "Based on the evaluation results from all models tested in Task 7, here's a comprehensive comparison:\n",
    "\n",
    "| Model | Accuracy | Precision (Neg/Pos) | Recall (Neg/Pos) | F1-Score (Neg/Pos) | ROC-AUC | \n",
    "|-------|----------|---------------------|------------------|-------------------|---------|\n",
    "| Logistic Regression | 95% | 93% / 99% | 99% / 92% | 0.96 / 0.95 | 0.955 | \n",
    "| Deep Neural Network | 99% | 100% / 99% | 99% / 100% | 0.99 / 0.99 | 0.9925 | \n",
    "| XGBoost | 99% | 99% / 99% | 99% / 99% | 0.99 / 0.99 | 0.9935 |\n",
    "| *Random Forest* | 99% | 99% / 99% | 99% / 99% | 0.99 / 0.99 | 0.9945 |\n",
    "| Linear SVM | 99% | 100% / 99% | 99% / 100% | 0.99 / 0.99 | 0.9935 | \n",
    "| RBF SVM | 99% | 100% / 99% | 99% / 100% | 0.99 / 0.99 | 0.9935 | \n",
    "| Naive Bayes | 50% | 50% / 82% | 100% / 0.01% | 0.67 / 0.02 | 0.5035 | \n",
    "\n",
    "##### Key Findings\n",
    "1.\tTop Performer by Metrics\n",
    "\n",
    "- Random Forest achieves the highest ROC-AUC (0.9945), along with 99% accuracy, precision, and recall for both classes. This makes it the strongest performer in terms of raw evaluation metrics.\n",
    "\n",
    "2.\tHigh-Performing Models\n",
    "\n",
    "- Deep Neural Network, XGBoost, Linear SVM, and RBF SVM also achieve 99% accuracy and very high precision and recall (99100%), performing closely to Random Forest.\n",
    "\n",
    "3.\tLogistic Regression Performance\n",
    "\n",
    "- Logistic Regression maintains excellent balance with 95% accuracy, strong F1-scores, very high negative recall (99%), and decent positive recall (92%). Its simplicity and interpretability make it a reliable choice, even if its ROC-AUC (0.955) is lower than ensemble models.\n",
    "\n",
    "4.\tPrecision vs Recall Trade-off\n",
    "\n",
    "- Most models show extremely high precision for the positive class (99100%). Logistic Regressions slightly lower positive recall is offset by balanced performance across both classes.\n",
    "\n",
    "5.\tPoor Performer\n",
    "\n",
    "- Naive Bayes suffers from severe class imbalance, with extremely low positive recall (0.01%) and F1-score, making it unsuitable for this task.\n",
    "\n",
    "##### Conclusion\n",
    "- **Best Choice by Metrics:** Random Forest is the strongest performer, achieving the highest ROC-AUC and excellent balance across all metrics.\n",
    "- **Reliable Simpler Model:** Logistic Regression is still attractive due to its interpretability and balanced performance, making it a good choice when simplicity is preferred over marginal gains in metrics.\n",
    "- **Key Takeaway:** Ensemble and non-linear models outperform simpler linear models in raw metrics, but simple models can still provide robust, interpretable performance when the dataset allows effective linear separation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846269d",
   "metadata": {},
   "source": [
    "##### Improvement\n",
    "Despite the excellent performance in most of our models, I suggest some improve \n",
    "- **Logistic Regression**: Positive recall is slightly lower\n",
    "    - Adjusting the decision threshold for classification to favor positive class\n",
    "\t- Using class weighting or oversampling (SMOTE) to balance classes\n",
    "\t- Feature engineering to capture non-linear patterns that logistic regression cant model\n",
    "- **Deep Neural Network**: Slight overfitting risk since accuracy is very high\n",
    "    - Regularization\n",
    "    - Hyperparameter tuning (layers, neurons, learning rate)\n",
    "    - Data augmentation for robustness\n",
    "- **XGBoost**: Marginally lower positive recall than DNN\n",
    "    - Tuning `scale_pos_weight` or class imbalance parameters\n",
    "    - Adjusting tree depth, learning rate, number of estimators\n",
    "    - Feature engineering \n",
    "- **Random Forest**: Slight overfitting due to many trees\n",
    "    - Tuning `max_depth`, `min_samples_leaf`, `max_features`\n",
    "    - Reducing correlation among trees\n",
    "    - Applying feature selection if dimensionality is high\n",
    "- **Linear SVM**: May struggle with non-linear pattern, which will be improved by **RBF SVM**\n",
    "- **RBF SVM**: Sensitive to hyperparameters and scalling\n",
    "    - Careful tuning `C` and `gamma`\n",
    "    - Scaling input features precisely\n",
    "    - Reducing overfitting via cross-validation or feature reduction\n",
    "- **Naive Bayes**: Severe class imbalance; almost zero positive recall\n",
    "    - Oversampling the minority class or using synthetic data (SMOTE)\n",
    "    - Using Complement Naive Bayes for imbalanced data\n",
    "    - Feature engineering to reduce noise and improve likelihood estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ee642",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "We are in 2025 right now, so use some Virtual Assistant such as ChatGPT (or better call API of LLM model) as the benchmark and find a way to run the test set in your course with ChatGPT to determine the sentiment. What is your conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dc959150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/bunnypro/Library/Mobile Documents/com~apple~CloudDocs/long_workspace/projects/machine_learning_lab\n",
      "Python path: ['/Users/bunnypro/miniconda3/envs/ml_env/lib/python311.zip', '/Users/bunnypro/miniconda3/envs/ml_env/lib/python3.11', '/Users/bunnypro/miniconda3/envs/ml_env/lib/python3.11/lib-dynload']\n",
      " Found benchmark.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "# Check current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Python path:\", sys.path[:3])  # Show first 3 paths\n",
    "\n",
    "# Verify benchmark.py exists\n",
    "benchmark_path = \"benchmark.py\"\n",
    "if os.path.exists(benchmark_path):\n",
    "    print(f\" Found {benchmark_path}\")\n",
    "else:\n",
    "    print(f\" {benchmark_path} not found in current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fd56c",
   "metadata": {},
   "source": [
    "This code requires running `benchmark.py`, a Python script I designed specifically for benchmarking with LLMs. It uses multithreading, which divides a single process into multiple threads (the smallest units of execution) that can run concurrently. This can improve performance, especially for tasks that can run in parallel, but it comes at a cost: CPU/GPU resources may become a bottleneck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648793d4",
   "metadata": {},
   "source": [
    "We will leverage these LLMs for this task: `gemini-2.5-pro`, `gemini-2.5-flash` and `gemini-2.5-flash-lite`. These are newest models from Google, available for everyone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c166acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running parallel benchmark...\n",
      "\n",
      "Evaluating model: gemini-2.5-pro (Parallel)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758647705.763175 3936586 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1/20\n",
      "Completed batch 2/20\n",
      "Completed batch 3/20\n",
      "Completed batch 4/20\n",
      "Completed batch 5/20\n",
      "Completed batch 6/20\n",
      "Completed batch 7/20\n",
      "Completed batch 8/20\n",
      "Completed batch 9/20\n",
      "Completed batch 10/20\n",
      "Completed batch 11/20\n",
      "Completed batch 12/20\n",
      "Completed batch 13/20\n",
      "Completed batch 14/20\n",
      "Completed batch 15/20\n",
      "Completed batch 16/20\n",
      "Completed batch 17/20\n",
      "Completed batch 18/20\n",
      "Completed batch 19/20\n",
      "Completed batch 20/20\n",
      "Total processing time (parallel): 410.54 seconds\n",
      "\n",
      "=== LLM: gemini-2.5-pro (Parallel) ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.95      0.99      0.97      1000\n",
      "    Positive       0.99      0.95      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[994   6]\n",
      " [ 53 947]]\n",
      "\n",
      "ROC-AUC: 0.9705\n",
      "\n",
      "Evaluating model: gemini-2.5-flash (Parallel)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758648116.321143 3936586 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1/20\n",
      "Completed batch 2/20\n",
      "Completed batch 3/20\n",
      "Completed batch 4/20\n",
      "Completed batch 5/20\n",
      "Completed batch 6/20\n",
      "Completed batch 7/20\n",
      "Completed batch 8/20\n",
      "Completed batch 9/20\n",
      "Completed batch 10/20\n",
      "Completed batch 11/20\n",
      "Completed batch 12/20\n",
      "Completed batch 13/20\n",
      "Completed batch 14/20\n",
      "Completed batch 15/20\n",
      "Completed batch 16/20\n",
      "Completed batch 17/20\n",
      "Completed batch 18/20\n",
      "Completed batch 19/20\n",
      "Completed batch 20/20\n",
      "Total processing time (parallel): 311.88 seconds\n",
      "\n",
      "=== LLM: gemini-2.5-flash (Parallel) ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.94      0.99      0.97      1000\n",
      "    Positive       0.99      0.94      0.96      1000\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.97      0.97      0.96      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[995   5]\n",
      " [ 65 935]]\n",
      "\n",
      "ROC-AUC: 0.965\n",
      "\n",
      "Evaluating model: gemini-2.5-flash-lite (Parallel)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758648428.217178 3936586 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 1/20\n",
      "Completed batch 2/20\n",
      "Completed batch 3/20\n",
      "Completed batch 4/20\n",
      "Completed batch 5/20\n",
      "Completed batch 6/20\n",
      "Completed batch 7/20\n",
      "Completed batch 8/20\n",
      "Completed batch 9/20\n",
      "Completed batch 10/20\n",
      "Completed batch 11/20\n",
      "Completed batch 12/20\n",
      "Completed batch 13/20\n",
      "Completed batch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 41.24746759s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 15/20\n",
      "Completed batch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 40.178078278s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 38.119139676s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 37.882926658s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed batch 18/20\n",
      "Completed batch 19/20\n",
      "Error in batch 17: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 33.823737552s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 33\n",
      "}\n",
      "]\n",
      "Completed batch 20/20\n",
      "Error in batch 19: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 15\n",
      "Please retry in 32.950902749s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "]\n",
      "Total processing time (parallel): 18.96 seconds\n",
      "\n",
      "=== LLM: gemini-2.5-flash-lite (Parallel) ===\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.95      1.00      0.97      1000\n",
      "    Positive       1.00      0.94      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "Confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[999   1]\n",
      " [ 57 943]]\n",
      "\n",
      "ROC-AUC: 0.971\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following lines to run benchmark.py if it exists\n",
    "# %run benchmark.py --parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069398b",
   "metadata": {},
   "source": [
    "### Model Comparison Table - Task 8\n",
    "\n",
    "Based on the evaluation results from all models tested in Task 8, here's a comprehensive comparison:\n",
    "\n",
    "| Model | Accuracy | Precision (Neg/Pos) | Recall (Neg/Pos) | F1-Score (Neg/Pos) | ROC-AUC |\n",
    "|-------|----------|---------------------|------------------|-------------------|---------|\n",
    "| Random Forest | 99% |  99% / 99% | 99% / 99% | 0.99 / 0.99 | 0.9945 |\n",
    "| `gemini-2.5-flash-lite` | 97% | 95% / 100% | 100% / 94% | 0.97 / 0.97 | 0.971 | \n",
    "| `gemini-2.5-pro` | 97% | 95% / 99% | 99% / 95% | 0.97 / 0.97 | 0.9705 |  \n",
    "| `gemini-2.5-flash` | 96% | 94% / 99% | 99% / 94% | 0.97 / 0.96 | 0.965 | \n",
    "| Logistic Regression | 95% | 93% / 99% | 99% / 92% | 0.96 / 0.95 | 0.955 | \n",
    "\n",
    "### Key Findings\n",
    "1.\tBest Model Overall\n",
    "- Again, the Random Forest outperforms others, achieving the best performance with regards of accuracy, recall and ROC-AUC.\n",
    "2.\tTop Performers\n",
    "- `gemini-2.5-flash-lite` slightly outperforms others overall, achieving the highest recall for the negative class (100%) and competitive metrics across all categories, including the highest ROC-AUC (0.971).\n",
    "- `gemini-2.5-pro` is a close second, maintaining high precision and recall for both classes. Its slight drop in negative class recall (99%) compared to flash-lite is minimal.'\n",
    "- `gemini-2.5-flash` also performs well but is slightly lower in overall accuracy and ROC-AUC.\n",
    "3.\tPrecision vs Recall Trade-off\n",
    "- Logistic Regression shows high precision for the positive class (99%) but slightly lower recall (92%), suggesting it is very confident when predicting positive sentiment but may miss some actual positives.\n",
    "- The Gemini models and Random Forest tend to balance precision and recall better across both classes, which is why their F1-scores are slightly higher.\n",
    "4.\tSurprising Result\n",
    "- Logistic Regression, despite being a simpler model, achieves competitive performance with 95% accuracy and 0.955 ROC-AUC. This indicates that for this dataset, complex LLM models are not drastically superior.\n",
    "5.\tWorst Performer\n",
    "- Among the LLMs, gemini-2.5-flash is marginally the weakest, with slightly lower accuracy, recall, and ROC-AUC compared to flash-lite and pro.\n",
    "\n",
    "### Note\n",
    "- LLM results are unstable, even when we use prompting techniques. The variability in responses means that running the same evaluation multiple times may yield different accuracy scores, unlike deterministic traditional ML models.\n",
    "- Despite their complexity and computational requirements, LLMs only marginally outperform simpler models like Logistic Regression (2-3% improvement in accuracy).\n",
    "- The cost-benefit analysis favors traditional ML: Logistic Regression achieves 95% accuracy with minimal computational resources, while LLMs require significantly more processing power for only modest gains.\n",
    "- Traditional models offer better interpretability and consistency, making them more suitable for production environments where reliability and explainability are crucial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25a832",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "Build quickly a UI to turn Sentiment Analysis into an application (with FrontEnd Streamlit, Gradio, Chainlit, Reflexe, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817dbfd",
   "metadata": {},
   "source": [
    "You can see the interface here:\n",
    "https://huggingface.co/spaces/tlong-ds/sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0afd84",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
